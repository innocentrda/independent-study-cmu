It's confirmed that karmada manages only resources deployed in karmada control contolplane. So how am I going to federate the ML workloads then? What I want is to be to distribute ML workloads across member clusters especially when some jobs require capabilities such GPUs that are not available one member cluster.

I want to deploy the minimum possible of kubeflow in karmada control plane (deployed in network-cluster) to allow propapagation. These the manifests I use to deploy full karmada. How can I disable unnecessary resources in karmada? And what should be deployed in member clusters (compute-cluster and storage-cluster)

Also show me how kubeflow resources will interact or communicate. Not that my clusters have metalLB which can provide services of type loadbalancer. So show how artifacts and metadata, etc will be able to be accessed by all members. 

:

 apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization sortOptions: order: legacy legacySortOptions: orderFirst: - Namespace - ResourceQuota - StorageClass - CustomResourceDefinition - MutatingWebhookConfiguration - ServiceAccount - PodSecurityPolicy - NetworkPolicy - Role - ClusterRole - RoleBinding - ClusterRoleBinding - ConfigMap - Secret - Endpoints - Service - LimitRange - PriorityClass - PersistentVolume - PersistentVolumeClaim - Deployment - StatefulSet - CronJob - PodDisruptionBudget orderLast: - ValidatingWebhookConfiguration resources: # Cert-Manager - ../common/cert-manager/base - ../common/cert-manager/kubeflow-issuer/base # Istio - ../common/istio-1-24/istio-crds/base - ../common/istio-1-24/istio-namespace/base - ../common/istio-1-24/istio-install/overlays/oauth2-proxy # oauth2-proxy # NOTE: only uncomment ONE of the following overlays, depending on your cluster type - ../common/oauth2-proxy/overlays/m2m-dex-only # for all clusters #- ../common/oauth2-proxy/overlays/m2m-dex-and-kind # for KIND clusters (allows K8S JWTs for gateway auth) #- ../common/oauth2-proxy/overlays/m2m-dex-and-eks # for EKS clusters (NOTE: requires you to configure issuer, see overlay) # Dex - ../common/dex/overlays/oauth2-proxy # KNative - ../common/knative/knative-serving/overlays/gateways # Uncomment the following line if knative-eventing is required # - ../common/knative/knative-eventing/base - ../common/istio-1-24/cluster-local-gateway/base # Kubeflow namespace - ../common/kubeflow-namespace/base # NetworkPolicies - ../common/networkpolicies/base # Kubeflow Roles - ../common/kubeflow-roles/base # Kubeflow Istio Resources - ../common/istio-1-24/kubeflow-istio-resources/base # Kubeflow Pipelines - ../apps/pipeline/upstream/env/cert-manager/platform-agnostic-multi-user # Katib - ../apps/katib/upstream/installs/katib-with-kubeflow # Central Dashboard - ../apps/centraldashboard/overlays/oauth2-proxy # Admission Webhook - ../apps/admission-webhook/upstream/overlays/cert-manager # Jupyter Web App - ../apps/jupyter/jupyter-web-app/upstream/overlays/istio # Notebook Controller - ../apps/jupyter/notebook-controller/upstream/overlays/kubeflow # Profiles + KFAM - ../apps/profiles/upstream/overlays/kubeflow # PVC Viewer - ../apps/pvcviewer-controller/upstream/base # Volumes Web App - ../apps/volumes-web-app/upstream/overlays/istio # Tensorboards Controller - ../apps/tensorboard/tensorboard-controller/upstream/overlays/kubeflow # Tensorboard Web App - ../apps/tensorboard/tensorboards-web-app/upstream/overlays/istio # Training Operator - ../apps/training-operator/upstream/overlays/kubeflow # User namespace - ../common/user-namespace/base # KServe - ../apps/kserve/kserve - ../apps/kserve/models-web-app/overlays/kubeflow # Ray is an experimental integration # Here is the documentation for Ray: https://docs.ray.io/en/latest/ # Here is the internal documentation for Ray: - ../experimental/ray/README.md # - ../experimental/ray/kuberay-operator/overlays/kubeflow components: # Pod Security Standards # https://kubernetes.io/docs/concepts/security/pod-security-standards/ # Uncomment to enable baseline level standards # - ../experimental/security/PSS/static/baseline # Uncomment to enable restricted level standards # - ../experimental/security/PSS/static/restricted # Uncomment to enable baseline level standards for dynamic namespaces # - ../experimental/security/PSS/dynamic/baseline # Uncomment to enable restricted level standards for dynamic namespaces # - ../experimental/security/PSS/dynamic/restricted
 
 
 Please give a full details Kustomization that should be deployed on karmada contrl plane, on compute cluater if any and on storage-cluster if any. And show which services should be updated to loadbalancer IP and which services which be updated accordingly. Please give enough details
 
 
 To give you an idea of how karmada work with an example of nginx deployment:

To be able to federate nginx replicas, nginx deployment manifest is submitted to karmada control plane and not deployed in meber clusters until the specifi policy is submitted to karmada control plane. Also k8s Deployment object (API) should be available in both members (compute-cluster and storage-cluster). After the policy is created then the deployment is created in member clusters according to the policy and the pods created acordingly.

Now imitated the same concepts to design the above scenario for kubeflow. At this stage let's scope to kubeflow pipelines. Having the notebook running on a jupyter server defining the pipeline and I want to executes the pods in member clusters federated by karmada control plane running in network-cluster.

